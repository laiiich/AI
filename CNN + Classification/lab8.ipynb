{"cells":[{"cell_type":"markdown","metadata":{"id":"RMjuKcSy8nem"},"source":["\n","## Image Classification (CNN)\n","\n","![animals.jpg](https://storage.googleapis.com/kaggle-datasets-images/1554380/2561346/c14cd64fb06842ad190298f9f4efaa49/dataset-cover.png?t=2021-08-26-19-14-08)"]},{"cell_type":"markdown","metadata":{"id":"2S4arEKfUWz2"},"source":["## Check if GPU is enabled"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":382,"status":"ok","timestamp":1713806855115,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"D_cgq_juiZMf","outputId":"322b76bb-d521-453b-c4f5-85fa4942aba5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n"," PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["# check your Colab device\n","import tensorflow as tf  # Import tensorflow library\n","import pprint            # Import pprint library for better print format\n","device_name = tf.config.list_physical_devices()  # A list of divece name, which could contain CPU and GPU\n","pprint.pprint(device_name)                       # Print the device_name"]},{"cell_type":"markdown","metadata":{"id":"EyXnL5rSUX3V"},"source":["***Note:*** If you use GPU too regularly, runtime durations will become shorter and shorter, and disconnections more frequent. The cooldown period before you can connect to another GPU will extend from hours to days to weeks."]},{"cell_type":"markdown","metadata":{"id":"hRxYd14OLSYP"},"source":["## **Lab Task Procedure**\n","0. Data preparation\n","1. Data preprocessing\n","2. Data generator **(Task 1)**\n","3. Build the model **(Task 2)**\n","4. Compile the model\n","5. Train the model\n","6. Evaluate the model\n","7. Save the model"]},{"cell_type":"markdown","metadata":{"id":"4FKDb00oMf9l"},"source":["## **Data Preparation**\n","\n","\n","1. Download the [Animal Species Classification Dataset](https://www.kaggle.com/datasets/utkarshsaxenadn/animal-image-classification-dataset) from [here](https://course.cse.ust.hk/comp2211/labs/lab8/animal-species-cls-v3.zip).\n","2. Upload this data to your Google Drive, under folder `comp2211/lab8`.\n","3. Run the following code cell to mount Google Drive and unzip the data.\n","\n","Note: If this lasts for more than three minutes, you may try deleting the previously unzipped folder on Google Drive and try again.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2886,"status":"ok","timestamp":1713806904027,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"1VfghOu7afM3","outputId":"42f9bf74-a4ce-4df9-f720-aed4bee38ac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/lab8\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd \"drive/MyDrive/lab8\"\n","#!unzip -q -o animal_species_v3.zip -d ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1713806904337,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"V6UUQs7vavtJ","outputId":"6d87aad3-2a1e-42d3-9d27-1f78129cc83b"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Beetle', 'Butterfly', 'Cat', 'Cow', 'Dog', 'Elephant', 'Gorilla', 'Hippo', 'Lizard', 'Monkey', 'Mouse', 'Panda', 'Spider', 'Tiger', 'Zebra']\n","Total categories: 15\n"]}],"source":["import os\n","data_dir = './animal_species_v3/train'\n","category_list = sorted(os.listdir(data_dir))\n","print(category_list)\n","print('Total categories:', len(category_list))"]},{"cell_type":"markdown","metadata":{"id":"QgwgslIrJ4aQ"},"source":["## **Animal Recognition**\n","---\n","About the data:\n","- Number of images: **7,500**.\n","- Number of classes: **15**.\n","- Image size: **(64, 64, 3)**."]},{"cell_type":"markdown","metadata":{"id":"KuK8n33Yw7tc"},"source":["Before data preprocessing, we visualize some of the images to get familiar with the data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":510,"output_embedded_package_id":"1r83F74ryKPNrVfhmncdUknx0hNX-Hjff"},"executionInfo":{"elapsed":45157,"status":"ok","timestamp":1713806952265,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"z4GMaGsKs--h","outputId":"cb09e0be-0871-4c00-8d7e-2b2eac527ca3"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import os, cv2, random\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(24,8))\n","for i, cate in enumerate(category_list):\n","  img_names = random.sample(os.listdir(data_dir+'/'+cate), k=5)\n","  for j, img_name in enumerate(img_names): # we only show 5 images of each category\n","    img = plt.imread(data_dir+'/'+cate+'/'+img_name) # read the image\n","    plt.subplot(5, 15, 15*j+i+1) # plot the same category at the same column\n","    plt.imshow(img)\n","    plt.axis('off')\n","    if j == 0: # only show category name at the first row\n","      plt.title(cate)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbdArU_kk-h5"},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import keras\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.callbacks import ModelCheckpoint"]},{"cell_type":"markdown","metadata":{"id":"bpzp1gc6x0Zk"},"source":["## 1. Data preprocessing\n","\n","We first construct a mapping from string-type category names to integer-type class indices, for later use."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1713806956542,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"bANmS4K6_XOs","outputId":"026dec6e-db53-44c6-8898-5bf5a5c0c490"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'Beetle': 0, 'Butterfly': 1, 'Cat': 2, 'Cow': 3, 'Dog': 4, 'Elephant': 5, 'Gorilla': 6, 'Hippo': 7, 'Lizard': 8, 'Monkey': 9, 'Mouse': 10, 'Panda': 11, 'Spider': 12, 'Tiger': 13, 'Zebra': 14}\n"]}],"source":["# Create a dict mapping the category name to the class index\n","# The number of label should be 15 (0 to 14)\n","cate2Idx = {cate:idx for idx, cate in enumerate(category_list)}\n","print(cate2Idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213797,"status":"ok","timestamp":1713807172400,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"dGlCR9m4tAyL","outputId":"a62dabea-ecc9-4186-8418-81587e04792f"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 15/15 [03:33<00:00, 14.23s/it]\n"]}],"source":["from tqdm import tqdm\n","x, y = [], []\n","for cate in tqdm(category_list):\n","  img_names = os.listdir(data_dir+'/'+cate)\n","  for img_name in img_names:\n","    img = cv2.imread(os.path.join(data_dir, cate, img_name))\n","    x.append(img)\n","    y.append(cate2Idx[cate])\n","x, y = np.asarray(x), np.asarray(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1713807214040,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"0nucmuBgMjc4","outputId":"d728e56c-7017-4158-fc60-5d2fe2b8d034"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7500, 64, 64, 3)\n","(7500,)\n"]}],"source":["# Check if the shapes are correct\n","print(x.shape)\n","print(y.shape)"]},{"cell_type":"markdown","metadata":{"id":"XMCmEEsN1_3V"},"source":["We further split the data to train and test sets with ratio 4:1 and convert the labels from integer to one-hot encoding with the following code cell."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXS-wvfjRm7G"},"outputs":[],"source":["# Split the dataset to train and test parts with ratio 4:1\n","# x_train is a NumPy array of RGB image data with shape (6000, 64, 64, 3)\n","# y_train is a NumPy array of labels (in range 0-14) with shape (6000, 15)\n","# x_test is a NumPy array of RGB image data with shape (1500, 64, 64, 3)\n","# y_test is a NumPy array of labels (in range 0-14) with shape (1500, 15)\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","\n","# There are 15 classes, represented as unique integers(0 to 14).\n","# Transform the integer into a 15-element binary vector (i.e., one-hot encoding).\n","y_train = to_categorical(y_train, len(category_list))\n","y_test = to_categorical(y_test, len(category_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1713807218647,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"H3DQPa-7yJDA","outputId":"939acd0a-4f73-4f17-b5f8-d2f2772935c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["(6000, 64, 64, 3)\n","(6000, 15)\n","(1500, 64, 64, 3)\n","(1500, 15)\n"]}],"source":["# Check if the shapes are correct\n","print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"NOq7mpKy-JBF"},"source":["## 2. Data generator\n","\n","### **Task 1**\n","\n","You need to add appropriate data augmentations to the data generator to avoid overfitting. By default, the data generator does not contain any data augmentation, but still runnable (you may try the default generator first to see how it performs).\n","\n","You may find this [webpage](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) useful for adding more augmentations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrA4mh7Ta8cc"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","def get_datagen() -> ImageDataGenerator:\n","  datagen = None\n","  ###############################################################################\n","  # TODO: your code starts here\n","\n","  datagen = ImageDataGenerator(rotation_range=30,\n","            width_shift_range=0.1,\n","            height_shift_range=0.1,\n","            shear_range=0.2,\n","            zoom_range=0.2,\n","            horizontal_flip=True,\n","            fill_mode='nearest')\n","\n","  # TODO: your code ends here\n","  ###############################################################################\n","  return datagen"]},{"cell_type":"markdown","metadata":{"id":"sD9vmwy---pz"},"source":["Run the following code cell to get a data generator `train_generator`, which will be used to produce augmented data during training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNGTD9T4-XXT"},"outputs":[],"source":["datagen = get_datagen()   # Instantiate a data generator\n","datagen.fit(x_train)      # Fit the generator to the training data for normalization\n","train_generator = datagen.flow(x_train, y_train, batch_size=128) #  The generator will be used during training"]},{"cell_type":"markdown","metadata":{"id":"pUmXtdNd1ONd"},"source":["## 3. Build the model\n","\n","### **Task 2**\n","\n","You need to build a CNN model for animal recognition. There is no restriction on the number of layers. You can use the following layers:\n","\n","* Convolution (`Conv2D`)\n","* Pooling (`MaxPooling2D`, `AveragePooling2D`)\n","* Fully-connected (`Dense`)\n","* Dropout (`Dropout`)\n","* Flatten (`Flatten`)\n","\n","Please keep the number of total parameters of your model within **less than 10 million.**\n","\n","For reference, our solution uses around 6.4 million parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"azRtraFsmqTr","executionInfo":{"status":"ok","timestamp":1713807860313,"user_tz":-480,"elapsed":352,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"83def268-8145-4dc0-d4e5-ab51e4de9385"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 62, 62, 32)        896       \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 31, 31, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 29, 29, 64)        18496     \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 14, 14, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_3 (Dropout)         (None, 14, 14, 64)        0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 12, 12, 128)       73856     \n","                                                                 \n"," max_pooling2d_5 (MaxPoolin  (None, 6, 6, 128)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 4, 4, 256)         295168    \n","                                                                 \n"," dropout_4 (Dropout)         (None, 4, 4, 256)         0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 4096)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 256)               1048832   \n","                                                                 \n"," dropout_5 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 15)                3855      \n","                                                                 \n","=================================================================\n","Total params: 1441103 (5.50 MB)\n","Trainable params: 1441103 (5.50 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Hint: The model from the review notebook could be a good starting point.\n","def custom_model():\n","  model = None\n","  ###############################################################################\n","  # TODO: your code starts here\n","  model = Sequential(  #Partly copy from lab8 review\n","    [Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)),  # Add a convolutional layer with 32 kernels, each of size 3x3\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),                            # Add another convolutional layer with 64 kernels, each of size 3x3\n","    MaxPooling2D(pool_size=(2, 2)),                                                       # Add a max pooling layer of size 2x2\n","    Dropout(0.2),                                                                         # Add a dropout layer to prevent a model from overfitting\n","    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n","    Dropout(0.3),\n","    Flatten(),                                                                            # Add a flatten layer to convert the pooled data to a single column\n","    Dense(units=256, activation='relu'),                                                  # Add a dense layer (fully-connected layer) and use ReLU activation function\n","    Dropout(0.3),\n","    Dense(units=15, activation='softmax')]\n","  )\n","\n","  # TODO: your code ends here\n","  ###############################################################################\n","  return model\n","\n","# Create the model (DO NOT include this in the submission file)\n","model = custom_model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"YqnopwQx4r_3"},"source":["## 4. Compile the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tn-OD4UPpafR"},"outputs":[],"source":["# Compile the model\n","# Use crossentropy loss function since there are two or more label classes\n","# Use adam algorithm (a stochastic gradient descent method)\n","# Use accuracy as metric\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","model.save('model_lab8.init.keras')"]},{"cell_type":"markdown","metadata":{"id":"KAoxaqjd4ytm"},"source":["## 5. Train the model\n","\n","Run the following code cell to start training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8HGyS_Y5mGDG","executionInfo":{"status":"ok","timestamp":1713808382626,"user_tz":-480,"elapsed":517783,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa1dac86-f07c-4ed1-e32b-017d3fd02566"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 25 variables whereas the saved optimizer has 1 variables. \n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","46/46 [==============================] - 9s 155ms/step - loss: 5.5204 - accuracy: 0.0800 - val_loss: 2.6601 - val_accuracy: 0.1207\n","Epoch 2/60\n","46/46 [==============================] - 8s 167ms/step - loss: 2.6251 - accuracy: 0.1342 - val_loss: 2.5765 - val_accuracy: 0.1487\n","Epoch 3/60\n","46/46 [==============================] - 8s 180ms/step - loss: 2.4933 - accuracy: 0.1938 - val_loss: 2.7246 - val_accuracy: 0.2047\n","Epoch 4/60\n","46/46 [==============================] - 7s 150ms/step - loss: 2.4350 - accuracy: 0.2115 - val_loss: 2.3579 - val_accuracy: 0.2213\n","Epoch 5/60\n","46/46 [==============================] - 9s 182ms/step - loss: 2.3124 - accuracy: 0.2538 - val_loss: 2.3059 - val_accuracy: 0.2740\n","Epoch 6/60\n","46/46 [==============================] - 8s 178ms/step - loss: 2.2247 - accuracy: 0.2933 - val_loss: 2.3380 - val_accuracy: 0.2647\n","Epoch 7/60\n","46/46 [==============================] - 7s 149ms/step - loss: 2.1676 - accuracy: 0.2967 - val_loss: 2.2866 - val_accuracy: 0.2733\n","Epoch 8/60\n","46/46 [==============================] - 7s 146ms/step - loss: 2.1131 - accuracy: 0.3203 - val_loss: 2.5356 - val_accuracy: 0.2560\n","Epoch 9/60\n","46/46 [==============================] - 8s 181ms/step - loss: 2.0540 - accuracy: 0.3432 - val_loss: 2.4339 - val_accuracy: 0.2640\n","Epoch 10/60\n","46/46 [==============================] - 7s 147ms/step - loss: 2.0429 - accuracy: 0.3465 - val_loss: 2.1728 - val_accuracy: 0.2927\n","Epoch 11/60\n","46/46 [==============================] - 9s 183ms/step - loss: 1.9368 - accuracy: 0.3750 - val_loss: 2.1278 - val_accuracy: 0.3380\n","Epoch 12/60\n","46/46 [==============================] - 9s 195ms/step - loss: 1.9205 - accuracy: 0.3838 - val_loss: 1.9897 - val_accuracy: 0.3827\n","Epoch 13/60\n","46/46 [==============================] - 7s 147ms/step - loss: 1.8756 - accuracy: 0.4025 - val_loss: 2.0100 - val_accuracy: 0.3687\n","Epoch 14/60\n","46/46 [==============================] - 8s 179ms/step - loss: 1.8380 - accuracy: 0.4140 - val_loss: 1.9604 - val_accuracy: 0.3773\n","Epoch 15/60\n","46/46 [==============================] - 8s 180ms/step - loss: 1.8192 - accuracy: 0.4190 - val_loss: 2.8114 - val_accuracy: 0.2687\n","Epoch 16/60\n","46/46 [==============================] - 7s 148ms/step - loss: 1.7597 - accuracy: 0.4445 - val_loss: 2.0744 - val_accuracy: 0.3767\n","Epoch 17/60\n","46/46 [==============================] - 9s 182ms/step - loss: 1.7447 - accuracy: 0.4383 - val_loss: 2.0172 - val_accuracy: 0.3833\n","Epoch 18/60\n","46/46 [==============================] - 7s 159ms/step - loss: 1.7382 - accuracy: 0.4483 - val_loss: 2.0820 - val_accuracy: 0.3747\n","Epoch 19/60\n","46/46 [==============================] - 7s 149ms/step - loss: 1.6991 - accuracy: 0.4553 - val_loss: 1.9839 - val_accuracy: 0.3973\n","Epoch 20/60\n","46/46 [==============================] - 8s 179ms/step - loss: 1.6776 - accuracy: 0.4688 - val_loss: 1.8291 - val_accuracy: 0.4093\n","Epoch 21/60\n","46/46 [==============================] - 8s 165ms/step - loss: 1.6691 - accuracy: 0.4723 - val_loss: 1.8855 - val_accuracy: 0.4220\n","Epoch 22/60\n","46/46 [==============================] - 8s 166ms/step - loss: 1.6273 - accuracy: 0.4832 - val_loss: 1.7209 - val_accuracy: 0.4660\n","Epoch 23/60\n","46/46 [==============================] - 8s 179ms/step - loss: 1.6140 - accuracy: 0.4873 - val_loss: 1.8223 - val_accuracy: 0.4353\n","Epoch 24/60\n","46/46 [==============================] - 7s 146ms/step - loss: 1.6530 - accuracy: 0.4860 - val_loss: 1.7573 - val_accuracy: 0.4620\n","Epoch 25/60\n","46/46 [==============================] - 8s 179ms/step - loss: 1.5980 - accuracy: 0.4888 - val_loss: 1.8844 - val_accuracy: 0.4233\n","Epoch 26/60\n","46/46 [==============================] - 8s 165ms/step - loss: 1.5627 - accuracy: 0.4975 - val_loss: 2.1827 - val_accuracy: 0.3680\n","Epoch 27/60\n","46/46 [==============================] - 7s 144ms/step - loss: 1.5325 - accuracy: 0.5063 - val_loss: 1.8451 - val_accuracy: 0.4373\n","Epoch 28/60\n","46/46 [==============================] - 7s 144ms/step - loss: 1.5136 - accuracy: 0.5192 - val_loss: 2.0256 - val_accuracy: 0.3727\n","Epoch 29/60\n","46/46 [==============================] - 8s 175ms/step - loss: 1.5130 - accuracy: 0.5150 - val_loss: 1.8327 - val_accuracy: 0.4227\n","Epoch 30/60\n","46/46 [==============================] - 8s 161ms/step - loss: 1.5246 - accuracy: 0.5132 - val_loss: 1.6954 - val_accuracy: 0.4733\n","Epoch 31/60\n","46/46 [==============================] - 8s 161ms/step - loss: 1.4840 - accuracy: 0.5262 - val_loss: 1.9890 - val_accuracy: 0.4067\n","Epoch 32/60\n","46/46 [==============================] - 10s 211ms/step - loss: 1.4576 - accuracy: 0.5325 - val_loss: 1.8045 - val_accuracy: 0.4667\n","Epoch 33/60\n","46/46 [==============================] - 7s 143ms/step - loss: 1.4477 - accuracy: 0.5363 - val_loss: 1.9734 - val_accuracy: 0.4140\n","Epoch 34/60\n","46/46 [==============================] - 8s 176ms/step - loss: 1.4472 - accuracy: 0.5318 - val_loss: 2.0662 - val_accuracy: 0.3953\n","Epoch 35/60\n","46/46 [==============================] - 9s 183ms/step - loss: 1.4117 - accuracy: 0.5508 - val_loss: 1.7564 - val_accuracy: 0.4747\n","Epoch 36/60\n","46/46 [==============================] - 7s 145ms/step - loss: 1.3796 - accuracy: 0.5617 - val_loss: 2.0242 - val_accuracy: 0.4313\n","Epoch 37/60\n","46/46 [==============================] - 7s 144ms/step - loss: 1.4094 - accuracy: 0.5542 - val_loss: 2.0421 - val_accuracy: 0.3913\n","Epoch 38/60\n","46/46 [==============================] - 8s 176ms/step - loss: 1.4366 - accuracy: 0.5398 - val_loss: 2.1004 - val_accuracy: 0.4047\n","Epoch 39/60\n","46/46 [==============================] - 7s 145ms/step - loss: 1.4072 - accuracy: 0.5537 - val_loss: 2.0013 - val_accuracy: 0.4173\n","Epoch 40/60\n","46/46 [==============================] - 7s 144ms/step - loss: 1.4122 - accuracy: 0.5407 - val_loss: 2.0962 - val_accuracy: 0.4107\n","Epoch 41/60\n","46/46 [==============================] - 8s 176ms/step - loss: 1.3710 - accuracy: 0.5597 - val_loss: 1.8941 - val_accuracy: 0.4427\n","Epoch 42/60\n","46/46 [==============================] - 7s 146ms/step - loss: 1.3483 - accuracy: 0.5693 - val_loss: 2.0023 - val_accuracy: 0.4387\n","Epoch 43/60\n","46/46 [==============================] - 9s 182ms/step - loss: 1.3106 - accuracy: 0.5870 - val_loss: 1.6594 - val_accuracy: 0.5187\n","Epoch 44/60\n","46/46 [==============================] - 8s 178ms/step - loss: 1.3327 - accuracy: 0.5745 - val_loss: 1.7604 - val_accuracy: 0.4907\n","Epoch 45/60\n","46/46 [==============================] - 7s 145ms/step - loss: 1.3084 - accuracy: 0.5777 - val_loss: 1.7722 - val_accuracy: 0.4907\n","Epoch 46/60\n","46/46 [==============================] - 10s 215ms/step - loss: 1.3185 - accuracy: 0.5860 - val_loss: 1.7603 - val_accuracy: 0.4793\n","Epoch 47/60\n","46/46 [==============================] - 7s 145ms/step - loss: 1.2766 - accuracy: 0.5948 - val_loss: 1.7675 - val_accuracy: 0.4733\n","Epoch 48/60\n","46/46 [==============================] - 8s 178ms/step - loss: 1.3085 - accuracy: 0.5813 - val_loss: 1.7407 - val_accuracy: 0.5013\n","Epoch 49/60\n","46/46 [==============================] - 7s 157ms/step - loss: 1.2693 - accuracy: 0.5933 - val_loss: 1.9992 - val_accuracy: 0.4413\n","Epoch 50/60\n","46/46 [==============================] - 7s 146ms/step - loss: 1.2965 - accuracy: 0.5913 - val_loss: 1.6773 - val_accuracy: 0.5287\n","Epoch 51/60\n","46/46 [==============================] - 8s 181ms/step - loss: 1.2473 - accuracy: 0.6087 - val_loss: 1.7935 - val_accuracy: 0.5020\n","Epoch 52/60\n","46/46 [==============================] - 7s 150ms/step - loss: 1.2445 - accuracy: 0.6017 - val_loss: 1.6686 - val_accuracy: 0.5220\n","Epoch 53/60\n","46/46 [==============================] - 7s 151ms/step - loss: 1.2302 - accuracy: 0.6060 - val_loss: 1.6296 - val_accuracy: 0.5400\n","Epoch 54/60\n","46/46 [==============================] - 7s 152ms/step - loss: 1.2089 - accuracy: 0.6130 - val_loss: 1.9305 - val_accuracy: 0.4660\n","Epoch 55/60\n","46/46 [==============================] - 8s 178ms/step - loss: 1.2203 - accuracy: 0.6142 - val_loss: 1.7195 - val_accuracy: 0.4980\n","Epoch 56/60\n","46/46 [==============================] - 7s 149ms/step - loss: 1.2195 - accuracy: 0.6103 - val_loss: 1.6825 - val_accuracy: 0.5087\n","Epoch 57/60\n","46/46 [==============================] - 8s 181ms/step - loss: 1.2754 - accuracy: 0.6000 - val_loss: 1.7244 - val_accuracy: 0.5000\n","Epoch 58/60\n","46/46 [==============================] - 8s 162ms/step - loss: 1.2152 - accuracy: 0.6077 - val_loss: 1.8818 - val_accuracy: 0.4753\n","Epoch 59/60\n","46/46 [==============================] - 7s 150ms/step - loss: 1.2374 - accuracy: 0.6020 - val_loss: 1.9224 - val_accuracy: 0.4747\n","Epoch 60/60\n","46/46 [==============================] - 9s 183ms/step - loss: 1.1689 - accuracy: 0.6292 - val_loss: 2.0932 - val_accuracy: 0.4740\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7abcb0f207f0>"]},"metadata":{},"execution_count":32}],"source":["model = keras.models.load_model('model_lab8.init.keras')  # Reset the model to last compilation\n","\n","checkpoint_callback = ModelCheckpoint(\n","    filepath='model_lab8.temp.keras',\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True)  # Save the model with the best validation accuracy seen so far at each epoch\n","\n","model.fit(train_generator,\n","         validation_data=(x_test, y_test),\n","         steps_per_epoch=len(x_train) / 128, epochs=60, # By default the model is trained with 60 epochs\n","         callbacks=[checkpoint_callback])               # You don't have to change the number of epochs, but you may do so if it is necessary"]},{"cell_type":"markdown","metadata":{"id":"WmxeTsXgnraN"},"source":["## 6. Evaluate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1253,"status":"ok","timestamp":1713808385783,"user":{"displayName":"Ch Lai","userId":"13055920353815892486"},"user_tz":-480},"id":"7QSK7wJ55f4j","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab06e020-461f-4ea5-a163-0584fa7de21a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation loss: 1.629609227180481\n","Validation accuracy: 0.5400000214576721\n"]}],"source":["model = keras.models.load_model('model_lab8.temp.keras')          # Restore the best model\n","val_loss, val_acc = model.evaluate(x_test, y_test, verbose=0)  # 'verbose=0' means no progress bar\n","print('Validation loss: {}'.format(val_loss))\n","print('Validation accuracy: {}'.format(val_acc))"]},{"cell_type":"markdown","metadata":{"id":"eBU_Mk1R4-yv"},"source":["## 7. Save the model\n","\n","Run the following code cell to save your model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7fNc59JO5LTN"},"outputs":[],"source":["# Save the mdoel to a keras file\n","model_name = 'model_lab8.keras'              # Define model name\n","model.save(model_name)  # Save the model"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}